{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4275f8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_list shape: (7442, 2048)\n",
      "filenames shape: (7442,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "# Read in features\n",
    "feature_list = pickle.load(open('./features-caltech101-resnet.pickle', 'rb'))\n",
    "filenames = pickle.load(open('./filenames-caltech101.pickle', 'rb'))\n",
    "feature_list = np.asarray(feature_list)\n",
    "filesnames = np.asarray(filenames)\n",
    "\n",
    "# print shape of feature_list and filenames\n",
    "print(\"feature_list shape:\", np.shape(feature_list))\n",
    "print(\"filenames shape:\", np.shape(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4440dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced shape of feature list after random projection: (7442, 300)\n",
      "Time:  0.5459894350000001\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#perform random projection to reduce dimensionality and create a \"reduced\" feature list\n",
    "from sklearn import random_projection\n",
    "\n",
    "reduced_feature_dims = 300\n",
    "transformer = random_projection.GaussianRandomProjection(n_components=reduced_feature_dims)\n",
    "FL_reduced = transformer.fit_transform(feature_list)\n",
    "print(\"reduced shape of feature list after random projection:\", FL_reduced.shape)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99537b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of binary feature list FL2= (7442, 300)\n",
      "samples is the number of images or rows = 7442\n",
      "number of attributes for each sample or image = 300\n"
     ]
    }
   ],
   "source": [
    "# convert the \"reduced\" (lower dimension) feature list into binary values\n",
    "FL2 = np.where(FL_reduced >= 0, 1, 0)\n",
    "print(\"shape of binary feature list FL2=\", np.shape(FL2))\n",
    "\n",
    "samples = FL2.shape[0]\n",
    "print(\"samples is the number of images or rows =\", samples)\n",
    "\n",
    "attributes = FL2.shape[1]\n",
    "print(\"number of attributes for each sample or image =\", attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3265fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find factor pairs of the number of rows (images)\n",
    "def factor_pairs(num):\n",
    "    factors = []\n",
    "    for i in range(1, int(num**0.5)+1):\n",
    "        if num % i == 0:\n",
    "            factors.append((i, num / i))\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bd0433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list all factors of the qty of attributes: [(1, 300.0), (2, 150.0), (3, 100.0), (4, 75.0), (5, 60.0), (6, 50.0), (10, 30.0), (12, 25.0), (15, 20.0)]\n",
      "number of factors in the factor list are: 9\n"
     ]
    }
   ],
   "source": [
    "# determine how many bins and rows per bin that you should create\n",
    "\n",
    "## here I'm inputting attributes, instead of samples, because we want to create bins by slicing up the\n",
    "## attributes, and comparing the attributes in each bin across all 7442 images.\n",
    "factor_list = factor_pairs(attributes)\n",
    "\n",
    "print(\"list all factors of the qty of attributes:\", factor_list)\n",
    "print(\"number of factors in the factor list are:\", np.shape(factor_list)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00f5ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bins will be: 15\n",
      "number of rows per bin will be: 20\n"
     ]
    }
   ],
   "source": [
    "#select the number of bins and rows per bin\n",
    "index = 9\n",
    "final_factor = factor_list[index-1][0]\n",
    "\n",
    "bins = int(final_factor)\n",
    "r_per_b = int(attributes/bins)\n",
    "\n",
    "print(\"number of bins will be:\", bins)\n",
    "print(\"number of rows per bin will be:\", r_per_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc6aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert each column in a bin from a numpy array into a binary string\n",
    "def convert(list):\n",
    "      \n",
    "    # Converting integer list to string list\n",
    "    s = [str(i) for i in list]\n",
    "      \n",
    "    # Join list items using join()\n",
    "    res = int(\"\".join(s))\n",
    "      \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c39753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hash each column in each bin to a matrix that has rows = number of images, and columns = number of bins.\n",
    "\n",
    "## initialize the columns you will use in each bin and the how you will step through the columns\n",
    "j_start = int(0)\n",
    "j_stop = int(FL2.shape[1] - r_per_b + 1)\n",
    "j_step = int(r_per_b)\n",
    "\n",
    "## create a matrix to store all the values you are about to hash\n",
    "matrix = np.zeros((FL2.shape[0],bins))\n",
    "\n",
    "## hash the dataset\n",
    "col_index = 0\n",
    "for col in range(j_start, j_stop, j_step):\n",
    "    for row in range(FL2.shape[0]):\n",
    "        bin_slice = FL2[row, col:int(col+j_step)]\n",
    "        binary_string = convert(bin_slice)\n",
    "        decimal = int(binary_string) ### the hash function we are using is to turn the binary into a decimal\n",
    "        matrix[row, col_index] = decimal\n",
    "    col_index = col_index + 1\n",
    "\n",
    "## check that the shape of the hashed matrix is correct:\n",
    "np.shape(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af769321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find images within each bin that are within a defined threshold of the target image\n",
    "\n",
    "## defined threshold\n",
    "threshold = 6\n",
    "\n",
    "## initialize the initial candidate pairs matrix\n",
    "icp = np.zeros(np.shape(matrix))\n",
    "\n",
    "## define the target image you want to find similarities against\n",
    "query_image_idx = random.randint(0, matrix.shape[0])\n",
    "\n",
    "## populate the icp matrix\n",
    "for col in range(matrix.shape[1]):\n",
    "    for row in range(matrix.shape[0]):\n",
    "        distance = matrix[query_image_idx, col] - matrix[row, col]\n",
    "        distance = abs(distance)\n",
    "        icp[row, col] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da6d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize a matrix of the top 5 matches within each bin\n",
    "mini_icp = np.zeros((threshold, bins))\n",
    "\n",
    "## sort the initial candidate pairs matrix and store the indices of the first \"threshold\" smallest values\n",
    "## using argsort. This gives the incides of the \"thershold\" images that were closest to the query image,\n",
    "## within each bin\n",
    "for col in range(icp.shape[1]):\n",
    "    indices = np.argsort(icp[:,col])\n",
    "    mini_icp[0:threshold, col] = indices[0:threshold]\n",
    "\n",
    "## flatten the matrix of the top \"threshold\" indices within each bin, and turn the indices from floats into integers\n",
    "flat_icp = mini_icp.flatten()\n",
    "flat_icp = flat_icp.astype(int)\n",
    "\n",
    "## count the frequency of the indices in the top \"threshold\" per bin\n",
    "frequency_by_index = np.bincount(flat_icp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "947fad4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2955, 3284, 5522, 5798, 5935, 5311])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top \"threshold\" indices across all the bins\n",
    "top_indices = np.argpartition(frequency_by_index, -threshold)[-threshold:]\n",
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f30746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename of query image:  ./gdrive/MyDrive/101_ObjectCategories/airplanes/image_0070.jpg\n",
      "filenames of results images:  ['./gdrive/MyDrive/101_ObjectCategories/wrench/image_0032.jpg'\n",
      " './gdrive/MyDrive/101_ObjectCategories/joshua_tree/image_0001.jpg'\n",
      " './gdrive/MyDrive/101_ObjectCategories/airplanes/image_0066.jpg'\n",
      " './gdrive/MyDrive/101_ObjectCategories/airplanes/image_0291.jpg'\n",
      " './gdrive/MyDrive/101_ObjectCategories/airplanes/image_0207.jpg'\n",
      " './gdrive/MyDrive/101_ObjectCategories/airplanes/image_0070.jpg']\n"
     ]
    }
   ],
   "source": [
    "#Compare the filename of the query image against the results\n",
    "\n",
    "# filename of query image\n",
    "print(\"filename of query image: \", filesnames[query_image_idx])\n",
    "\n",
    "## using the indices of the top matches, pull those images\n",
    "top_thresh = filesnames[top_indices]\n",
    "print(\"filenames of results images: \", top_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8b870b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_concatenated_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7m/68w31f_506g6d764v38mw6kw0000gn/T/ipykernel_9735/3256791723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_concatenated_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_image_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_concatenated_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# display the query image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_concatenated_images' is not defined"
     ]
    }
   ],
   "source": [
    "query_image = get_concatenated_images([query_image_idx], 300)\n",
    "results_image = get_concatenated_images(top_indices, 200)\n",
    "\n",
    "# display the query image\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(query_image)\n",
    "plt.title(\"query image (%d)\" % query_image_idx)\n",
    "\n",
    "# display the resulting images\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(results_image)\n",
    "plt.title(\"result images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
